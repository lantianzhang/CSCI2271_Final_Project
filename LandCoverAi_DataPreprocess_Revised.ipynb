{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af4a4a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note this should be run in the same folder as the landcover.ai dataset.\n",
    "#Data (Version 1) sourced here https://landcover.ai.linuxpolska.com/\n",
    "#Produced Zipfile to be upl\n",
    "\n",
    "\n",
    "import os\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "56a57d98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\micha\\anaconda3\\lib\\site-packages (4.8.1.78)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\micha\\appdata\\roaming\\python\\python311\\site-packages (from opencv-python) (1.24.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0fe5542d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imporant params to be included\n",
    "num_classes = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1573b671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed M-33-20-D-c-4-2 1/41\n",
      "Processed M-33-20-D-d-3-3 2/41\n",
      "Processed M-33-32-B-b-4-4 3/41\n",
      "Processed M-33-48-A-c-4-4 4/41\n",
      "Processed M-33-7-A-d-2-3 5/41\n",
      "Processed M-33-7-A-d-3-2 6/41\n",
      "Processed M-34-32-B-a-4-3 7/41\n",
      "Processed M-34-32-B-b-1-3 8/41\n",
      "Processed M-34-5-D-d-4-2 9/41\n",
      "Processed M-34-51-C-b-2-1 10/41\n",
      "Processed M-34-51-C-d-4-1 11/41\n",
      "Processed M-34-55-B-b-4-1 12/41\n",
      "Processed M-34-56-A-b-1-4 13/41\n",
      "Processed M-34-6-A-d-2-2 14/41\n",
      "Processed M-34-65-D-a-4-4 15/41\n",
      "Processed M-34-65-D-c-4-2 16/41\n",
      "Processed M-34-65-D-d-4-1 17/41\n",
      "Processed M-34-68-B-a-1-3 18/41\n",
      "Processed M-34-77-B-c-2-3 19/41\n",
      "Processed N-33-104-A-c-1-1 20/41\n",
      "Processed N-33-119-C-c-3-3 21/41\n",
      "Processed N-33-130-A-d-3-3 22/41\n",
      "Processed N-33-130-A-d-4-4 23/41\n",
      "Processed N-33-139-C-d-2-2 24/41\n",
      "Processed N-33-139-C-d-2-4 25/41\n",
      "Processed N-33-139-D-c-1-3 26/41\n",
      "Processed N-33-60-D-c-4-2 27/41\n",
      "Processed N-33-60-D-d-1-2 28/41\n",
      "Processed N-33-96-D-d-1-1 29/41\n",
      "Processed N-34-106-A-b-3-4 30/41\n",
      "Processed N-34-106-A-c-1-3 31/41\n",
      "Processed N-34-140-A-b-3-2 32/41\n",
      "Processed N-34-140-A-b-4-2 33/41\n",
      "Processed N-34-140-A-d-3-4 34/41\n",
      "Processed N-34-140-A-d-4-2 35/41\n",
      "Processed N-34-61-B-a-1-1 36/41\n",
      "Processed N-34-66-C-c-4-3 37/41\n",
      "Processed N-34-77-A-b-1-4 38/41\n",
      "Processed N-34-94-A-b-2-4 39/41\n",
      "Processed N-34-97-C-b-1-2 40/41\n",
      "Processed N-34-97-D-c-2-4 41/41\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints',\n",
       " 'DataPreprocess.ipynb',\n",
       " 'DataPreprocess_Revised.ipynb',\n",
       " 'images',\n",
       " 'landcover_prep_grey_class.zip',\n",
       " 'masks',\n",
       " 'output',\n",
       " 'split.py',\n",
       " 'test.txt',\n",
       " 'train.txt',\n",
       " 'train_class_distribution.txt',\n",
       " 'train_class_weights.txt',\n",
       " 'val.txt']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Expected to run in the same directory as the landcover files\n",
    "destination_dir = './'  # Change this to your desired directory\n",
    "\n",
    "\n",
    "output_dir = os.path.join(destination_dir, \"output/\")\n",
    "if not os.path.exists(output_dir):\n",
    "    # Change the current working directory to the destination directory\n",
    "    os.chdir(destination_dir)\n",
    "\n",
    "    # Run split.py\n",
    "    !python split.py\n",
    "\n",
    "    # List the contents of the destination directory\n",
    "    os.listdir(destination_dir)\n",
    "else:\n",
    "    print(\"Output directory already exists. Skipping split.py.\")\n",
    "\n",
    "\n",
    "os.listdir(destination_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ec9ca981",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_cpu_cores = os.cpu_count()\n",
    "# print(f\"Number of CPU cores: {num_cpu_cores}\")\n",
    "# num_workers = num_cpu_cores - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6f0a6ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augmentation(sample):\n",
    "    input_image, input_mask = sample\n",
    "    IMG_SIZE = 512\n",
    "\n",
    "    to_tensor = transforms.ToTensor()\n",
    "\n",
    "    input_image = to_tensor(input_image)\n",
    "    \n",
    "    # Avoid conversion / normalization\n",
    "    input_mask_np = np.array(input_mask, dtype=np.int64)\n",
    "    input_mask = torch.as_tensor(input_mask_np, dtype=torch.int8).unsqueeze(0)\n",
    "\n",
    "    return input_image, input_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4037dc6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data_dir, txt_file, transform=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transform\n",
    "        txt_file_path = os.path.join(data_dir, txt_file)\n",
    "        with open(txt_file_path, 'r') as file:\n",
    "            self.prefixes = [line.strip() for line in file]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.prefixes)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        prefix = self.prefixes[idx]\n",
    "        image_path = os.path.join(self.data_dir, 'output', f'{prefix}.jpg')\n",
    "        mask_path = os.path.join(self.data_dir, 'output', f'{prefix}_m.png') #grey->m because I realized the issue\n",
    "        image = Image.open(image_path)\n",
    "        mask = Image.open(mask_path).convert('L')\n",
    "#         print(mask)\n",
    "\n",
    "        if self.transform:\n",
    "            sample = (image, mask)\n",
    "            sample = self.transform(sample)\n",
    "            image, mask = sample\n",
    "\n",
    "        return image, mask\n",
    "\n",
    "# Define GPU transformation\n",
    "gpu_transform = transforms.Compose([\n",
    "    augmentation,\n",
    "])\n",
    "\n",
    "# Example usage\n",
    "train_dataset = CustomDataset(data_dir=destination_dir, txt_file='train.txt', transform=gpu_transform)\n",
    "val_dataset = CustomDataset(data_dir=destination_dir, txt_file='val.txt', transform=gpu_transform)\n",
    "test_dataset = CustomDataset(data_dir=destination_dir, txt_file='test.txt', transform=gpu_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ef4117ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution written to ./class_distribution.txt\n",
      "Class weights written to ./class_weights.txt\n"
     ]
    }
   ],
   "source": [
    "# Calculate metrics\n",
    "def calculate_class_weights_and_distribution(dataset, num_classes, save_to_files=False):\n",
    "    # Initialize arrays to store the counts of each class\n",
    "    class_counts = torch.zeros(num_classes)\n",
    "    total_count = len(dataset)\n",
    "\n",
    "    # Iterate through the dataset to count class occurrences\n",
    "    for i in range(total_count):\n",
    "        _, mask = dataset[i]\n",
    "        unique_values, value_counts = torch.unique(mask, return_counts=True)\n",
    "\n",
    "        # Increment class counts based on unique values\n",
    "        for unique_value, value_count in zip(unique_values, value_counts):\n",
    "            class_counts[unique_value.item()] += value_count\n",
    "\n",
    "    # Set weights based on the distribution\n",
    "    class_weights = class_counts / total_count\n",
    "\n",
    "    # Weights are inversly proportional to counts\n",
    "    total_weight = class_weights.sum()\n",
    "    class_weights = total_weight / class_weights\n",
    "\n",
    "    # Convert tensors to lists for JSON serialization\n",
    "    class_weights_list = class_weights.tolist()\n",
    "    class_distribution = class_counts.tolist()\n",
    "    \n",
    "    if save_to_files:\n",
    "        distribution_file_path = \"./class_distribution.txt\"\n",
    "        with open(distribution_file_path, \"w\") as distribution_file:\n",
    "            for count in class_distribution:\n",
    "                distribution_file.write(f\"{count}\\n\")\n",
    "\n",
    "        print(f\"Class distribution written to {distribution_file_path}\")\n",
    "\n",
    "        # Save class weights to a text file if requested\n",
    "        weights_file_path = \"./class_weights.txt\"\n",
    "        with open(weights_file_path, \"w\") as weights_file:\n",
    "            for weight in class_weights:\n",
    "                weights_file.write(f\"{weight}\\n\")\n",
    "\n",
    "        print(f\"Class weights written to {weights_file_path}\")\n",
    "\n",
    "    return class_weights_list, class_distribution\n",
    "\n",
    "# Usage\n",
    "class_weights, class_distribution = calculate_class_weights_and_distribution(train_dataset, num_classes, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cec3c3bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zipped files to landcover_prep_prepped_class.zip\n"
     ]
    }
   ],
   "source": [
    "# Name of the zip file you want to create\n",
    "zip_filename = \"landcover_prep_prepped_class.zip\"\n",
    "\n",
    "# Open a zip file for writing\n",
    "with zipfile.ZipFile(zip_filename, \"w\", zipfile.ZIP_DEFLATED) as zipf:\n",
    "    # Iterate through .txt files in the current directory and add them\n",
    "    for root, dirs, files in os.walk(\".\"):\n",
    "        for file in files:\n",
    "            if file.endswith(\".txt\"):\n",
    "                file_path = os.path.join(root, file)\n",
    "                zipf.write(file_path, os.path.relpath(file_path, \".\"))\n",
    "\n",
    "    # Recursively add the contents of the ./output directory to the zip file\n",
    "    for root, dirs, files in os.walk(\"./output\"):\n",
    "        for file in files:\n",
    "            file_path = os.path.join(root, file)\n",
    "            # Add the file to the zip with a relative path including the \"output\" directory\n",
    "            zipf.write(file_path, os.path.relpath(file_path, \".\"))\n",
    "\n",
    "print(f\"Zipped files to {zip_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b285fef3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
